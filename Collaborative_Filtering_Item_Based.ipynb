{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems on Purchased Data\n",
    "## Item-Item Based Filtering\n",
    "###### The most popular and simple approach to CF is the item-item collaborative filtering. To construct a recommendation for a user, we build the item matrix by finding the k-nearest neighbor items using Cosine, Pearson or Jaccard similarity. We then construct the prediction for each user-item based on the item-item similarity matrix calculated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import sparse\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>nb_purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  ItemID  nb_purchased\n",
       "0  100002      51             1\n",
       "1  100002      52             3\n",
       "2  100002      53             1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Data \n",
    "df=pd.read_csv(\"C:/Users/alorenzodebrionne/Documents/Python/purchased_data.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userID: 1892\n",
      "ItemID: 17626\n"
     ]
    }
   ],
   "source": [
    "print(\"userID:\", df.userID.nunique())\n",
    "print(\"ItemID:\", df.ItemID.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To ensure statistical significance users with less than 5 items, and items with less than 10 ratings are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter on Items with have at least 10 users\n",
    "item_count = df.groupby(['ItemID']).size().reset_index(name='counts').sort_values(['counts'], ascending=False)\n",
    "list_items = item_count[item_count['counts']>175]\n",
    "\n",
    "# Filter on Users with at least 5 items\n",
    "user_count = df.groupby(['userID']).size().reset_index(name='counts').sort_values(['counts'], ascending=False)\n",
    "list_users = user_count[user_count['counts']>40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_items= list_items['ItemID']\n",
    "list_users= list_users['userID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID: 1716\n",
      "ItemID: 53\n"
     ]
    }
   ],
   "source": [
    "df= df[df['ItemID'].isin(list_items)]\n",
    "df= df[df['userID'].isin(list_users)]\n",
    "print(\"UserID:\", df.userID.nunique())\n",
    "print(\"ItemID:\", df.ItemID.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We convert the table to a 2D Matrix, the matrix is very sparse because all items are not bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pivot = df.pivot(index='userID', columns='ItemID').nb_purchased\n",
    "userID = pd.DataFrame(df_pivot.index)#Keep UserID's \n",
    "\n",
    "# Replace all NaN per zeros\n",
    "df_pivot=df_pivot.fillna(0)\n",
    "\n",
    "#Reset Index\n",
    "df_pivot = df_pivot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Magnitude Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score creation\n",
    "magnitude = np.sqrt(np.square(df_pivot).sum(axis=1))\n",
    "df_pivot = df_pivot.divide(magnitude,axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the train set and test set\n",
    "### Process for Data Masking\n",
    "##### Randomly assign 0 values to the training set - Test set is a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a copy of the original set to be the test set\n",
    "def make_train(df, pct_test = 0.25):\n",
    "    \n",
    "    test_set=df.copy() \n",
    "    training_set=df.copy() \n",
    "\n",
    "    colnames = list(training_set.columns.values) #List Products Names\n",
    "\n",
    "    training_set_array= np.array(training_set) #Transform to Array\n",
    "\n",
    "    nonzero_inds=training_set_array.nonzero() #Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs=list(zip(nonzero_inds[0],nonzero_inds[1])) #zip these pairs together of user, uitem index into list\n",
    "    random.seed(123) #set the random seed to zero for reproducibility\n",
    "\n",
    "    num_samples=int(np.ceil(pct_test*len(nonzero_pairs))) #round the number of samples needed to the nearest integer\n",
    "    samples=random.sample(nonzero_pairs,num_samples) #Sample a random number of the user-item pairs without replacement\n",
    "    user_inds=[index[0] for index in samples] #get the user row indices\n",
    "    item_inds=[index[1] for index in samples] #get the item column indices\n",
    "    training_set_array[user_inds,item_inds] = 0 #Assign all of the randomly chosen user-item pairs to zero\n",
    "\n",
    "    training_set=pd.DataFrame(training_set_array, columns=colnames)\n",
    "\n",
    "    return training_set, test_set, list(set(user_inds))\n",
    "training_set, test_set, item_users_altered = make_train(df_pivot,pct_test=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-Item Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cosine similarity between products\n",
    "def calculate_similarity(data_items):\n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    sim = pd.DataFrame(data=similarities,index=data_items.columns,columns=data_items.columns)\n",
    "    return sim\n",
    "\n",
    "\n",
    "#Build item-item similarity matrix\n",
    "cosine_sim = calculate_similarity(training_set)\n",
    "\n",
    "ncol = len(training_set.columns)\n",
    "data_neighbours=pd.DataFrame(index=cosine_sim.columns,columns=range(1,ncol+1))\n",
    "for i in range(0,len(cosine_sim.columns)):\n",
    "    data_neighbours.iloc[i,:ncol]=cosine_sim.iloc[0:,i].sort_values(ascending=False)[:ncol].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation per User - Top-N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Empty Datasets to Append the user's recommendation\n",
    "df_rec = pd.DataFrame([])\n",
    "df_top_N  = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "n_items, n_users = df_pivot.shape\n",
    "\n",
    "while i < n_users:\n",
    "    productsofusers = training_set.iloc[i]\n",
    "    productsofusers=productsofusers[productsofusers>0].index.values #Keep only indexes\n",
    "\n",
    "    #construct the neighbourhood from the most similar items to the ones our user already have\n",
    "    most_similar_to_likes = data_neighbours.loc[productsofusers]\n",
    "    similar_list=most_similar_to_likes.values.tolist()\n",
    "    similar_list=list(set([item for sublist in similar_list for item in sublist]))\n",
    "    neighbourhood=cosine_sim[similar_list].loc[similar_list]\n",
    "    #vector with the neighbourhood and user likes\n",
    "    user_vector=training_set.iloc[i].loc[similar_list]\n",
    "    #calculate score\n",
    "    score=neighbourhood.dot(user_vector).div(neighbourhood.sum(axis=1))                                  \n",
    "\n",
    "    #drop products users already have\n",
    "    score=score.drop(productsofusers)\n",
    "\n",
    "    #creation of the table with recommendations for each users\n",
    "    df_top_N = pd.DataFrame(score.nlargest(3),columns=['score']) #top 10 products\n",
    "    df_top_N['index_u'] = i #find the id of the user i\n",
    "    df_top_N['userID'] = userID[userID.index==i].userID.tolist()[0] #find the id of the user i\n",
    "    df_rec = df_rec.append(df_top_N) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "#### Create the Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP=  1089 FP=  3042 FN=  2750 TN=  56199\n"
     ]
    }
   ],
   "source": [
    "#Variables  Initialization\n",
    "true_positive=0\n",
    "false_positive=0\n",
    "true_negative=0\n",
    "false_negative=0\n",
    "\n",
    "for user in item_users_altered: #Iterate through each user that had an item altered\n",
    "    actual =pd.DataFrame(test_set.iloc[user,:]) # List all Item for the User\n",
    "    actual.columns=  ['ItemID']\n",
    "    training =pd.DataFrame(training_set.iloc[user,:]) # List all Item for the Use\n",
    "    training.columns= ['ItemID']\n",
    "    \n",
    "    training= training[training['ItemID'] == 0] # Item-User Hidden\n",
    "    actual= actual[actual['ItemID'] > 0]  # Original Data \n",
    "        \n",
    "    must_be_recommend= pd.merge(training,actual,left_index=True, right_index=True, how='inner').index.values\n",
    "    is_recommend = df_rec[(df_rec['index_u']==user)].index.values\n",
    "    not_recommend = np.array(pd.DataFrame(training[~training.index.isin(is_recommend)].index))\n",
    "\n",
    "    #condition positive\n",
    "    for i in is_recommend:\n",
    "        if (i in must_be_recommend):\n",
    "            true_positive=true_positive+1\n",
    "        else:\n",
    "            false_positive=false_positive+1\n",
    "    #condition negative\n",
    "    for i in not_recommend:\n",
    "        if (i in must_be_recommend):\n",
    "            false_negative=false_negative+1\n",
    "        else:\n",
    "            true_negative=true_negative+1   \n",
    " \n",
    "print('TP= ', true_positive, 'FP= ', false_positive,'FN= ', false_negative,'TN= ', true_negative)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
